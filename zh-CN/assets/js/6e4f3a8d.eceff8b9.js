"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[738],{3905:(e,t,o)=>{o.d(t,{Zo:()=>p,kt:()=>b});var n=o(7294);function a(e,t,o){return t in e?Object.defineProperty(e,t,{value:o,enumerable:!0,configurable:!0,writable:!0}):e[t]=o,e}function r(e,t){var o=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),o.push.apply(o,n)}return o}function i(e){for(var t=1;t<arguments.length;t++){var o=null!=arguments[t]?arguments[t]:{};t%2?r(Object(o),!0).forEach((function(t){a(e,t,o[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(o)):r(Object(o)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(o,t))}))}return e}function s(e,t){if(null==e)return{};var o,n,a=function(e,t){if(null==e)return{};var o,n,a={},r=Object.keys(e);for(n=0;n<r.length;n++)o=r[n],t.indexOf(o)>=0||(a[o]=e[o]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)o=r[n],t.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(e,o)&&(a[o]=e[o])}return a}var l=n.createContext({}),c=function(e){var t=n.useContext(l),o=t;return e&&(o="function"==typeof e?e(t):i(i({},t),e)),o},p=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var o=e.components,a=e.mdxType,r=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=c(o),m=a,b=u["".concat(l,".").concat(m)]||u[m]||d[m]||r;return o?n.createElement(b,i(i({ref:t},p),{},{components:o})):n.createElement(b,i({ref:t},p))}));function b(e,t){var o=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=o.length,i=new Array(r);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:a,i[1]=s;for(var c=2;c<r;c++)i[c]=o[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,o)}m.displayName="MDXCreateElement"},7486:(e,t,o)=>{o.r(t),o.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var n=o(7462),a=(o(7294),o(3905));const r={sidebar_position:3},i="Obstacle location",s={unversionedId:"guides/dora-drives/obstacle_location",id:"guides/dora-drives/obstacle_location",title:"Obstacle location",description:"The carla simulator gives us the possibility to work with many more sensors than just a camera feed. We can emulate an LIDAR, IMU, Depth sensor, Segmentation sensor...",source:"@site/i18n/zh-CN/docusaurus-plugin-content-docs/current/guides/dora-drives/obstacle_location.mdx",sourceDirName:"guides/dora-drives",slug:"/guides/dora-drives/obstacle_location",permalink:"/zh-CN/docs/guides/dora-drives/obstacle_location",draft:!1,editUrl:"https://crowdin.com/dora-rs/zh-CN",tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"guides",previous:{title:"Carla Simulator",permalink:"/zh-CN/docs/guides/dora-drives/carla"},next:{title:"Planning",permalink:"/zh-CN/docs/guides/dora-drives/planning"}},l={},c=[],p={toc:c},u="wrapper";function d(e){let{components:t,...o}=e;return(0,a.kt)(u,(0,n.Z)({},p,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"obstacle-location"},"Obstacle location"),(0,a.kt)("p",null,"The carla simulator gives us the possibility to work with many more sensors than just a camera feed. We can emulate an LIDAR, IMU, Depth sensor, Segmentation sensor..."),(0,a.kt)("p",null,"Let's use the LIDAR sensor to locate the exact position of the obstacle that has been located by ",(0,a.kt)("inlineCode",{parentName:"p"},"yolov5"),"."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"The lidar point cloud is an array of ",(0,a.kt)("inlineCode",{parentName:"p"},"x, y, z, intensity")," points."),(0,a.kt)("p",{parentName:"blockquote"},"The coordinates are based on Unreal Engine coordinate system which is: "),(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"z is up")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"x is forward")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("p",{parentName:"li"},"y is right"),(0,a.kt)("p",{parentName:"li"},"More info: ",(0,a.kt)("a",{parentName:"p",href:"https://www.techarthub.com/a-practical-guide-to-unreal-engine-4s-coordinate-system/"},"https://www.techarthub.com/a-practical-guide-to-unreal-engine-4s-coordinate-system/")))),(0,a.kt)("p",{parentName:"blockquote"},"and within carla documentation: ",(0,a.kt)("a",{parentName:"p",href:"https://carla.readthedocs.io/en/latest/ref_sensors/#lidar-sensor"},"https://carla.readthedocs.io/en/latest/ref_sensors/#lidar-sensor")),(0,a.kt)("p",{parentName:"blockquote"},"You can also check velodyne reference: ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/ros-drivers/velodyne/blob/master/velodyne_pcl/README.md"},"https://github.com/ros-drivers/velodyne/blob/master/velodyne_pcl/README.md"))),(0,a.kt)("p",null,"To get the obstacle location, we are going to compute the angle of every points in the point cloud. We can then map the angle of each pixel of the bounding box to a real point and therefore infere its location. We then transform the coordinate from the relative lIDAR coordinate system into a global coordinate system by adding the current position of the LIDAR sensor. The code can be found here: ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/dora-rs/dora-drives/blob/main/operators/obstacle_location_op.py"},(0,a.kt)("inlineCode",{parentName:"a"},"operators/obstacle_location_op.py")),". "),(0,a.kt)("p",null,"To use the obstacle location, just add it to the graph with:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"nodes:\n  - id: oasis_agent\n    custom:\n      inputs:\n        tick: dora/timer/millis/400\n      outputs:\n        - position\n        - speed\n        - image\n        - objective_waypoints\n        - lidar_pc\n        - opendrive\n      source: shell\n      # With Carla_source_node\n      args: python3 ../../carla/carla_source_node.py\n      #\n      # Or with the OASIS AGENT\n      #\n      # args: >\n        # python3 $SIMULATE --output \n        # --oasJson --criteriaConfig $CRITERIA\n        # --openscenario $XOSC\n        # --agent $TEAM_AGENT\n        # --agentConfig $TEAM_AGENT_CONF\n        # --destination $DESTINATION\n  \n  - id: yolov5\n    operator: \n      outputs:\n        - bbox\n      inputs:\n        image: oasis_agent/image\n      python: ../../operators/yolov5_op.py\n\n  - id: obstacle_location_op\n    operator: \n      outputs:\n        - obstacles\n      inputs:\n        lidar_pc: oasis_agent/lidar_pc\n        obstacles_bbox: yolov5/bbox\n        position: oasis_agent/position\n      python: ../../operators/obstacle_location_op.py\n\n  - id: plot\n    operator:\n      python: ../../operators/plot.py\n      inputs:\n        image: oasis_agent/image\n        obstacles_bbox: yolov5/bbox\n        position: oasis_agent/position\n        obstacles: obstacle_location_op/obstacles\n")),(0,a.kt)("p",null,"To run: "),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"dora up\ndora start graphs/oasis/oasis_agent_obstacle_location.yaml --attach\n")),(0,a.kt)("p",null,"You should be able to see a dot within the bounding box representing the estimated location in global coordinate of the obstacle."),(0,a.kt)("p",{align:"center"},(0,a.kt)("img",{src:"/img/obstacle_location.png",width:"800"})),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"For more information on ",(0,a.kt)("inlineCode",{parentName:"p"},"obstacle_location"),", go on ",(0,a.kt)("a",{parentName:"p",href:"/docs/nodes_operators/obstacle_location_op"},"our ",(0,a.kt)("inlineCode",{parentName:"a"},"obstacle_location")," detail page"))))}d.isMDXComponent=!0}}]);