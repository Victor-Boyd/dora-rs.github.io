"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[2294],{3905:(n,e,o)=>{o.d(e,{Zo:()=>_,kt:()=>b});var t=o(7294);function a(n,e,o){return e in n?Object.defineProperty(n,e,{value:o,enumerable:!0,configurable:!0,writable:!0}):n[e]=o,n}function l(n,e){var o=Object.keys(n);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(n);e&&(t=t.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),o.push.apply(o,t)}return o}function r(n){for(var e=1;e<arguments.length;e++){var o=null!=arguments[e]?arguments[e]:{};e%2?l(Object(o),!0).forEach((function(e){a(n,e,o[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(o)):l(Object(o)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(o,e))}))}return n}function i(n,e){if(null==n)return{};var o,t,a=function(n,e){if(null==n)return{};var o,t,a={},l=Object.keys(n);for(t=0;t<l.length;t++)o=l[t],e.indexOf(o)>=0||(a[o]=n[o]);return a}(n,e);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(n);for(t=0;t<l.length;t++)o=l[t],e.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(n,o)&&(a[o]=n[o])}return a}var s=t.createContext({}),p=function(n){var e=t.useContext(s),o=e;return n&&(o="function"==typeof n?n(e):r(r({},e),n)),o},_=function(n){var e=p(n.components);return t.createElement(s.Provider,{value:e},n.children)},c="mdxType",u={inlineCode:"code",wrapper:function(n){var e=n.children;return t.createElement(t.Fragment,{},e)}},d=t.forwardRef((function(n,e){var o=n.components,a=n.mdxType,l=n.originalType,s=n.parentName,_=i(n,["components","mdxType","originalType","parentName"]),c=p(o),d=a,b=c["".concat(s,".").concat(d)]||c[d]||u[d]||l;return o?t.createElement(b,r(r({ref:e},_),{},{components:o})):t.createElement(b,r({ref:e},_))}));function b(n,e){var o=arguments,a=e&&e.mdxType;if("string"==typeof n||a){var l=o.length,r=new Array(l);r[0]=d;var i={};for(var s in e)hasOwnProperty.call(e,s)&&(i[s]=e[s]);i.originalType=n,i[c]="string"==typeof n?n:a,r[1]=i;for(var p=2;p<l;p++)r[p]=o[p];return t.createElement.apply(null,r)}return t.createElement.apply(null,o)}d.displayName="MDXCreateElement"},462:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>s,contentTitle:()=>r,default:()=>u,frontMatter:()=>l,metadata:()=>i,toc:()=>p});var t=o(7462),a=(o(7294),o(3905));const l={},r="Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u64cd\u4f5c\u7b26",i={unversionedId:"nodes_operators/obstacle_location_op",id:"nodes_operators/obstacle_location_op",title:"Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u64cd\u4f5c\u7b26",description:"Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u64cd\u4f5c\u7b26\u5339\u914d\u5e26\u6709\u6df1\u5ea6\u6846\u67b6\u7684\u8fb9\u754c\u6846\uff0c\u7528\u4e8e\u67e5\u627e\u969c\u788d\u7269\u7684\u8fd1\u4f3c\u4f4d\u7f6e\u3002",source:"@site/i18n/zh-CN/docusaurus-plugin-content-docs/current/nodes_operators/obstacle_location_op.md",sourceDirName:"nodes_operators",slug:"/nodes_operators/obstacle_location_op",permalink:"/zh-CN/docs/nodes_operators/obstacle_location_op",draft:!1,editUrl:"https://crowdin.com/dora-rs/zh-CN",tags:[],version:"current",frontMatter:{},sidebar:"nodes_operators",previous:{title:"MiDaS (Mixed Frequency Data Sampling Regression Models, \u6df7\u9891\u6570\u636e\u91c7\u6837\u56de\u5f52\u6a21\u578b)",permalink:"/zh-CN/docs/nodes_operators/midas_op"},next:{title:"PID Control (PID:\u504f\u5dee\u7684\u6bd4\u4f8bP-\u79ef\u5206I-\u5fae\u5206D  \u63a7\u5236) \u64cd\u4f5c\u7b26",permalink:"/zh-CN/docs/nodes_operators/pid_control_op"}},s={},p=[{value:"\u8f93\u5165",id:"\u8f93\u5165",level:2},{value:"\u8f93\u51fa",id:"\u8f93\u51fa",level:2},{value:"\u793a\u4f8b\u7ed8\u5236 \uff08\u8fb9\u754c\u6846\u4e2d\u95f4\u7684\u7eff\u70b9\uff09",id:"\u793a\u4f8b\u7ed8\u5236-\u8fb9\u754c\u6846\u4e2d\u95f4\u7684\u7eff\u70b9",level:2},{value:"\u56fe\u63cf\u8ff0",id:"\u56fe\u63cf\u8ff0",level:2},{value:"\u56fe\u53ef\u89c6\u5316",id:"\u56fe\u53ef\u89c6\u5316",level:2},{value:"\u65b9\u6cd5",id:"\u65b9\u6cd5",level:2},{value:"<code>__init__()</code>",id:"__init__",level:3},{value:"<code>.on_event(...)</code>",id:"on_event",level:3},{value:"<code>.on_input(...)</code>",id:"on_input",level:3}],_={toc:p},c="wrapper";function u(n){let{components:e,...o}=n;return(0,a.kt)(c,(0,t.Z)({},_,o,{components:e,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"obstacle-location-\u969c\u788d\u7269\u4f4d\u7f6e-\u64cd\u4f5c\u7b26"},"Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u64cd\u4f5c\u7b26"),(0,a.kt)("p",null,"Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u64cd\u4f5c\u7b26\u5339\u914d\u5e26\u6709\u6df1\u5ea6\u6846\u67b6\u7684\u8fb9\u754c\u6846\uff0c\u7528\u4e8e\u67e5\u627e\u969c\u788d\u7269\u7684\u8fd1\u4f3c\u4f4d\u7f6e\u3002"),(0,a.kt)("p",null,"\u5176\u4e2d\u6709\u4e24\u4e2a\u903b\u8f91\uff1a"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u4e00\u4e2a\u662f\u7528\u4e8e\u8f66\u9053\u68c0\u6d4b\u7684\u63a5\u5730\u70b9\u3002"),(0,a.kt)("li",{parentName:"ul"},"\u4e00\u4e2a\u662f\u8fb9\u754c\u6846\u969c\u788d\u7269\u5b9a\u4f4d\u3002")),(0,a.kt)("p",null,"\u8fd9\u4e24\u79cd\u903b\u8f91\u90fd\u662f\u57fa\u4e8e\u5bf9\u6fc0\u5149\u96f7\u8fbe 3D \u70b9\u5728 2D \u7a7a\u95f4\u4e2d\u7684\u6295\u5f71\u8fdb\u884c\u8ba1\u7b97\uff0c\u7136\u540e\u91cd\u7528\u7d22\u5f15\u6765\u83b7\u53d6 3D \u4f4d\u7f6e\u3002"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u5728\u63a5\u5730\u70b9\u68c0\u6d4b\u7684\u60c5\u51b5\u4e0b\uff0c\u8fd1\u4f3c\u503c\u57fa\u4e8e\u4e00\u4e2a K\u90bb\u8fd1\u56de\u5f52\uff0c\u56e0\u4e3a\u6211\u4eec\u53ef\u80fd\u6ca1\u6709\u8db3\u591f\u7684\u5730\u9762\u6570\u636e\u3002"),(0,a.kt)("li",{parentName:"ul"},"\u5728\u8fb9\u754c\u6846\u7684\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u4f7f\u7528\u8fb9\u754c\u6846\u5185\u7684\u7b2c\u4e00\u4e2a\u5206\u4f4d\u6570\u6700\u8fd1\u70b9\u6765\u4f30\u8ba1\u8ddd\u79bb\u3002 \u6211\u4eec\u4f7f\u7528\u7b2c\u4e00\u4e2a\u5206\u4f4d\u6570\u6700\u8fd1\u70b9\u6765\u6d88\u9664\u566a\u58f0\u3002")),(0,a.kt)("p",null,"\u5c06\u6fc0\u5149\u96f7\u8fbe\u70b9\u4e91\u6295\u5f71\u5230 2D \u4e2d\u7684\u673a\u68b0\u6027\u4e5f\u7528\u4e8e ",(0,a.kt)("inlineCode",{parentName:"p"},"plot.py")," \u64cd\u4f5c\u7b26\u4e2d\u3002 \u60a8\u53ef\u4ee5\u4f7f\u7528\u5176\u4e2d\u8f93\u5165 ",(0,a.kt)("inlineCode",{parentName:"p"},"lidar_pc")," \u5e2e\u52a9\u60a8\u8fdb\u884c\u8c03\u8bd5\u3002"),(0,a.kt)("h2",{id:"\u8f93\u5165"},"\u8f93\u5165"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"2D \u969c\u788d\u7269\u8fb9\u754c\u6846\u3002")),(0,a.kt)("h2",{id:"\u8f93\u51fa"},"\u8f93\u51fa"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u969c\u788d\u7269\u7684 3D \u4f4d\u7f6e\u4f5c\u4e3a\u70b9\u3002")),(0,a.kt)("h2",{id:"\u793a\u4f8b\u7ed8\u5236-\u8fb9\u754c\u6846\u4e2d\u95f4\u7684\u7eff\u70b9"},"\u793a\u4f8b\u7ed8\u5236 \uff08\u8fb9\u754c\u6846\u4e2d\u95f4\u7684\u7eff\u70b9\uff09"),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://i.imgur.com/Aq33qy5.png",alt:"Imgur"})),(0,a.kt)("h2",{id:"\u56fe\u63cf\u8ff0"},"\u56fe\u63cf\u8ff0"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},"  - id: obstacle_location_op\n    operator: \n      outputs:\n        - obstacles\n      inputs:\n        lidar_pc: oasis_agent/lidar_pc\n        obstacles_bbox: yolov5/bbox\n        position: oasis_agent/position\n      python: ../../operators/obstacle_location_op.py\n")),(0,a.kt)("h2",{id:"\u56fe\u53ef\u89c6\u5316"},"\u56fe\u53ef\u89c6\u5316"),(0,a.kt)("mermaid",{value:"        flowchart TB\n  oasis_agent\nsubgraph yolov5\n  yolov5/op[op]\nend\nsubgraph fot_op\n  fot_op/op[op]\nend\nsubgraph obstacle_location_op\n  obstacle_location_op/op[op]\nend\n  oasis_agent -- lidar_pc --\x3e obstacle_location_op/op\n  yolov5/op -- bbox as obstacles_bbox --\x3e obstacle_location_op/op\n  oasis_agent -- position --\x3e obstacle_location_op/op\n  obstacle_location_op/op -- obstacles --\x3e fot_op/op"}),(0,a.kt)("h2",{id:"\u65b9\u6cd5"},"\u65b9\u6cd5"),(0,a.kt)("h3",{id:"__init__"},(0,a.kt)("inlineCode",{parentName:"h3"},"__init__()")),(0,a.kt)("details",null,(0,a.kt)("summary",null,"\u6e90\u7801"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"    def __init__(self):\n        self.point_cloud = []\n        self.camera_point_cloud = []\n        self.ground_point_cloud = []\n        self.camera_ground_point_cloud = []\n        self.last_point_cloud = []\n        self.last_camera_point_cloud = []\n        self.obstacles = []\n        self.obstacles_bbox = []\n        self.position = []\n        self.lanes = []\n\n\n"))),(0,a.kt)("h3",{id:"on_event"},(0,a.kt)("inlineCode",{parentName:"h3"},".on_event(...)")),(0,a.kt)("details",null,(0,a.kt)("summary",null,"\u6e90\u7801"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\n    def on_event(\n        self,\n        dora_event: dict,\n        send_output: Callable[[str, bytes], None],\n    ) -> DoraStatus:\n        if dora_event["type"] == "INPUT":\n            return self.on_input(dora_event, send_output)\n        return DoraStatus.CONTINUE\n\n\n'))),(0,a.kt)("h3",{id:"on_input"},(0,a.kt)("inlineCode",{parentName:"h3"},".on_input(...)")),(0,a.kt)("details",null,(0,a.kt)("summary",null,"\u6e90\u7801"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\n    def on_input(\n        self,\n        dora_input: dict,\n        send_output: Callable[[str, bytes], None],\n    ):\n        if "lidar_pc" == dora_input["id"]:\n            point_cloud = np.array(dora_input["value"])\n            point_cloud = point_cloud.reshape((-1, 3))\n\n            # \u4ece Velodyne\u6fc0\u5149\u96f7\u8fbe\u8f74 \u81f3 \u76f8\u673a\u8f74\n            # \u4ece Velodyne\u6fc0\u5149\u96f7\u8fbe\u8f74:\n            # x -> \u5411\u524d, y -> \u5411\u53f3, z -> \u81f3\u9876\n            # \u81f3 \u76f8\u673a\u8f74:\n            # x -> \u5411\u53f3, y -> \u81f3\u5e95, z -> \u5411\u524d\n            point_cloud = np.dot(\n                point_cloud,\n                VELODYNE_MATRIX,\n            )\n\n            # \u4ec5 \u5411\u524d \u70b9 ( forward = z > 0.1 )\n            point_cloud = point_cloud[np.where(point_cloud[:, 2] > 0.1)]\n\n            # \u79fb\u9664\u5730\u9762\u70b9\u3002 Above lidar only ( bottom = y < 1.0 )\n            above_ground_point_index = np.where(point_cloud[:, 1] < 1.0)\n            point_cloud = point_cloud[above_ground_point_index]\n            self.ground_point_cloud = point_cloud[above_ground_point_index == False]\n\n            # 3D \u6570\u7ec4 -> 2D \u6570\u7ec4 \u4e0e index_x -> pixel x, index_y -> pixel_y, value -> z\n            camera_point_cloud = local_points_to_camera_view(\n                point_cloud, INTRINSIC_MATRIX\n            ).T\n            self.camera_ground_point_cloud = local_points_to_camera_view(\n                self.ground_point_cloud, INTRINSIC_MATRIX\n            ).T\n\n            self.camera_point_cloud = camera_point_cloud\n            self.point_cloud = point_cloud\n\n        elif "position" == dora_input["id"]:\n            # \u6dfb\u52a0\u4f20\u611f\u5668\u53d8\u6362\n            self.position = dora_input["value"].to_numpy()\n            self.extrinsic_matrix = get_extrinsic_matrix(\n                get_projection_matrix(self.position)\n            )\n\n        elif "lanes" == dora_input["id"]:\n            lanes = np.array(dora_input["value"]).reshape((-1, 60, 2))\n\n            knnr = KNeighborsRegressor(n_neighbors=4)\n            knnr.fit(self.camera_ground_point_cloud[:, :2], self.ground_point_cloud)\n\n            processed_lanes = []\n            for lane in lanes:\n                lane_location = knnr.predict(lane)\n                lane_location = np.array(lane_location)\n\n                lane_location = np.hstack(\n                    (\n                        lane_location,\n                        np.ones((lane_location.shape[0], 1)),\n                    )\n                )\n                lane_location = np.dot(lane_location, self.extrinsic_matrix.T)[:, :3]\n                processed_lanes.append(lane_location)\n            processed_lanes = pa.array(np.array(processed_lanes, np.float32).ravel())\n\n            send_output("global_lanes", processed_lanes, dora_input["metadata"])\n\n        elif "obstacles_bbox" == dora_input["id"]:\n            if len(self.position) == 0 or len(self.point_cloud) == 0:\n                return DoraStatus.CONTINUE\n\n            # bbox = np.array([[min_x, max_x, min_y, max_y, confidence, label], ... n_bbox ... ])\n            self.obstacles_bbox = np.array(dora_input["value"]).reshape((-1, 6))\n\n            obstacles_with_location = []\n            for obstacle_bb in self.obstacles_bbox:\n                [min_x, max_x, min_y, max_y, confidence, label] = obstacle_bb\n                z_points = self.point_cloud[\n                    np.where(\n                        (self.camera_point_cloud[:, 0] > min_x)\n                        & (self.camera_point_cloud[:, 0] < max_x)\n                        & (self.camera_point_cloud[:, 1] > min_y)\n                        & (self.camera_point_cloud[:, 1] < max_y)\n                    )\n                ]\n                if len(z_points) > 0:\n                    closest_point = z_points[\n                        z_points[:, 2].argsort()[int(len(z_points) / 4)]\n                    ]\n                    obstacles_with_location.append(closest_point)\n            if len(obstacles_with_location) > 0:\n                obstacles_with_location = np.array(obstacles_with_location)\n                obstacles_with_location = np.hstack(\n                    (\n                        obstacles_with_location,\n                        np.ones((obstacles_with_location.shape[0], 1)),\n                    )\n                )\n                obstacles_with_location = np.dot(\n                    obstacles_with_location, self.extrinsic_matrix.T\n                )[:, :3]\n\n                predictions = get_predictions(\n                    self.obstacles_bbox, obstacles_with_location\n                )\n                predictions_bytes = pa.array(np.array(predictions, np.float32).ravel())\n\n                send_output("obstacles", predictions_bytes, dora_input["metadata"])\n            else:\n                send_output(\n                    "obstacles",\n                    pa.array(np.array([]).ravel()),\n                    dora_input["metadata"],\n                )\n        return DoraStatus.CONTINUE\n\n\n'))))}u.isMDXComponent=!0}}]);