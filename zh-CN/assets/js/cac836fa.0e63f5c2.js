"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[8266],{3905:(e,n,t)=>{t.d(n,{Zo:()=>u,kt:()=>_});var r=t(7294);function o(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function a(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?a(Object(t),!0).forEach((function(n){o(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):a(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,r,o=function(e,n){if(null==e)return{};var t,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||(o[t]=e[t]);return o}(e,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)t=a[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var i=r.createContext({}),p=function(e){var n=r.useContext(i),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},u=function(e){var n=p(e.components);return r.createElement(i.Provider,{value:n},e.children)},d="mdxType",c={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},m=r.forwardRef((function(e,n){var t=e.components,o=e.mdxType,a=e.originalType,i=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),d=p(t),m=o,_=d["".concat(i,".").concat(m)]||d[m]||c[m]||a;return t?r.createElement(_,l(l({ref:n},u),{},{components:t})):r.createElement(_,l({ref:n},u))}));function _(e,n){var t=arguments,o=n&&n.mdxType;if("string"==typeof e||o){var a=t.length,l=new Array(a);l[0]=m;var s={};for(var i in n)hasOwnProperty.call(n,i)&&(s[i]=n[i]);s.originalType=e,s[d]="string"==typeof e?e:o,l[1]=s;for(var p=2;p<a;p++)l[p]=t[p];return r.createElement.apply(null,l)}return r.createElement.apply(null,t)}m.displayName="MDXCreateElement"},9232:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>c,frontMatter:()=>a,metadata:()=>s,toc:()=>p});var r=t(7462),o=(t(7294),t(3905));const a={},l="Strong Sort (strong deep learning for simple online and realtime tracking, \u5f3a\u5316\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u7b80\u5355\u5728\u7ebf\u4e0e\u5b9e\u65f6\u8ddf\u8e2a) \u64cd\u4f5c\u7b26",s={unversionedId:"nodes_operators/strong_sort_op",id:"nodes_operators/strong_sort_op",title:"Strong Sort (strong deep learning for simple online and realtime tracking, \u5f3a\u5316\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u7b80\u5355\u5728\u7ebf\u4e0e\u5b9e\u65f6\u8ddf\u8e2a) \u64cd\u4f5c\u7b26",description:"Strong Sort (strong deep learning for simple online and realtime tracking, \u5f3a\u5316\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u7b80\u5355\u5728\u7ebf\u4e0e\u5b9e\u65f6\u8ddf\u8e2a)  \u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60 \u6765\u552f\u4e00\u6807\u8bc6\u8fb9\u754c\u6846\u4ee5\u4fbf\u901a\u8fc7\u56fe\u50cf\u6d41\u8ddf\u8e2a\u5b83\u4eec\u3002",source:"@site/i18n/zh-CN/docusaurus-plugin-content-docs/current/nodes_operators/strong_sort_op.md",sourceDirName:"nodes_operators",slug:"/nodes_operators/strong_sort_op",permalink:"/zh-CN/docs/nodes_operators/strong_sort_op",draft:!1,editUrl:"https://crowdin.com/dora-rs/zh-CN",tags:[],version:"current",frontMatter:{},sidebar:"nodes_operators",previous:{title:"Plot(\u7ed8\u5236) \u64cd\u4f5c\u7b26",permalink:"/zh-CN/docs/nodes_operators/plot"},next:{title:"Webcam (\u6444\u50cf\u5934) \u64cd\u4f5c\u7b26",permalink:"/zh-CN/docs/nodes_operators/webcam_op"}},i={},p=[{value:"\u8f93\u5165",id:"\u8f93\u5165",level:2},{value:"\u8f93\u51fa",id:"\u8f93\u51fa",level:2},{value:"\u793a\u4f8b\u7ed8\u5236 (\u8ddf\u8e2a\u76f8\u5e94\u4e8e\u84dd\u8272 # id )",id:"\u793a\u4f8b\u7ed8\u5236-\u8ddf\u8e2a\u76f8\u5e94\u4e8e\u84dd\u8272--id-",level:2},{value:"\u56fe\u63cf\u8ff0",id:"\u56fe\u63cf\u8ff0",level:2},{value:"\u56fe\u53ef\u89c6\u5316",id:"\u56fe\u53ef\u89c6\u5316",level:2},{value:"\u65b9\u6cd5",id:"\u65b9\u6cd5",level:2},{value:"<code>__init__()</code>",id:"__init__",level:3},{value:"<code>.on_event(...)</code>",id:"on_event",level:3},{value:"<code>.on_input(...)</code>",id:"on_input",level:3}],u={toc:p},d="wrapper";function c(e){let{components:n,...t}=e;return(0,o.kt)(d,(0,r.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"strong-sort-strong-deep-learning-for-simple-online-and-realtime-tracking-\u5f3a\u5316\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u7b80\u5355\u5728\u7ebf\u4e0e\u5b9e\u65f6\u8ddf\u8e2a-\u64cd\u4f5c\u7b26"},"Strong Sort (strong deep learning for simple online and realtime tracking, \u5f3a\u5316\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u7b80\u5355\u5728\u7ebf\u4e0e\u5b9e\u65f6\u8ddf\u8e2a) \u64cd\u4f5c\u7b26"),(0,o.kt)("p",null,"Strong Sort (strong deep learning for simple online and realtime tracking, \u5f3a\u5316\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u7684\u7b80\u5355\u5728\u7ebf\u4e0e\u5b9e\u65f6\u8ddf\u8e2a)  \u4f7f\u7528\u6df1\u5ea6\u5b66\u4e60 \u6765\u552f\u4e00\u6807\u8bc6\u8fb9\u754c\u6846\u4ee5\u4fbf\u901a\u8fc7\u56fe\u50cf\u6d41\u8ddf\u8e2a\u5b83\u4eec\u3002"),(0,o.kt)("h2",{id:"\u8f93\u5165"},"\u8f93\u5165"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"\u56fe\u50cf: \u9ad8 x \u5bbd x BGR array\u3002"),(0,o.kt)("li",{parentName:"ul"},"bbox: N_BBOX, X_MIN, X_MAX, Y_MIN, Y_MAX, CONDIDENCE, CLASS, array")),(0,o.kt)("h2",{id:"\u8f93\u51fa"},"\u8f93\u51fa"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"obstacles_id: x1, x2, y1, y2 track_id, class_id, conf")),(0,o.kt)("h2",{id:"\u793a\u4f8b\u7ed8\u5236-\u8ddf\u8e2a\u76f8\u5e94\u4e8e\u84dd\u8272--id-"},"\u793a\u4f8b\u7ed8\u5236 (\u8ddf\u8e2a\u76f8\u5e94\u4e8e\u84dd\u8272 # id )"),(0,o.kt)("p",null,(0,o.kt)("img",{parentName:"p",src:"https://i.imgur.com/ozO1y7l.gif",alt:"\u56fe\u50cf"})),(0,o.kt)("h2",{id:"\u56fe\u63cf\u8ff0"},"\u56fe\u63cf\u8ff0"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-yaml"},"  - id: yolov5\n    operator: \n      outputs:\n        - obstacles_id\n      inputs:\n        image: webcam/image\n        bbox: yolov5/bbox\n      python: ../../operators/strong_sort_op.py\n")),(0,o.kt)("h2",{id:"\u56fe\u53ef\u89c6\u5316"},"\u56fe\u53ef\u89c6\u5316"),(0,o.kt)("mermaid",{value:"        flowchart TB\n  oasis_agent -- image --\x3e strong_sort/op\n  yolov5/op -- bbox as obstacles_bbox --\x3e strong_sort/op"}),(0,o.kt)("h2",{id:"\u65b9\u6cd5"},"\u65b9\u6cd5"),(0,o.kt)("h3",{id:"__init__"},(0,o.kt)("inlineCode",{parentName:"h3"},"__init__()")),(0,o.kt)("details",null,(0,o.kt)("summary",null,"\u6e90\u7801"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'    def __init__(self):\n        model = StrongSORT(\n            "osnet_x0_25_msmt17.pt",\n            torch.device("cuda"),\n            False,\n        )\n        model.model.warmup()\n        self.model = model\n        self.frame = []\n\n\n'))),(0,o.kt)("h3",{id:"on_event"},(0,o.kt)("inlineCode",{parentName:"h3"},".on_event(...)")),(0,o.kt)("details",null,(0,o.kt)("summary",null,"\u6e90\u7801"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\n    def on_event(\n        self,\n        dora_event: dict,\n        send_output: Callable[[str, bytes], None],\n    ) -> DoraStatus:\n        if dora_event["type"] == "INPUT":\n            return self.on_input(dora_event, send_output)\n        return DoraStatus.CONTINUE\n\n\n'))),(0,o.kt)("h3",{id:"on_input"},(0,o.kt)("inlineCode",{parentName:"h3"},".on_input(...)")),(0,o.kt)("details",null,(0,o.kt)("summary",null,"\u6e90\u7801"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},'\n    def on_input(\n        self,\n        dora_input: dict,\n        send_output: Callable[[str, bytes], None],\n    ) -> DoraStatus:\n        if dora_input["id"] == "image":\n            frame = np.array(\n                dora_input["value"],\n                np.uint8,\n            ).reshape((IMAGE_HEIGHT, IMAGE_WIDTH, 4))\n\n            self.frame = frame[:, :, :3]\n\n        elif dora_input["id"] == "obstacles_bbox" and len(self.frame) != 0:\n            obstacles = np.array(dora_input["value"]).reshape((-1, 6))\n            if obstacles.shape[0] == 0:\n                # self.model.increment_ages()\n                send_output(\n                    "obstacles_id",\n                    pa.array(np.array([]).ravel()),\n                    dora_input["metadata"],\n                )\n                return DoraStatus.CONTINUE\n\n            # \u540e\u52a0\u5de5 yolov5\n            xywhs = xxyy2xywh(obstacles[:, 0:4])\n            confs = obstacles[:, 4]\n            clss = obstacles[:, 5]\n            with torch.no_grad():\n                outputs = np.array(\n                    self.model.update(xywhs, confs, clss, self.frame)\n                ).astype("int32")\n                if len(outputs) != 0:\n                    outputs = outputs[\n                        :, [0, 2, 1, 3, 4, 5, 6]\n                    ]  # xyxy -> x1, x2, y1, y2 track_id, class_id, conf\n\n                    send_output(\n                        "obstacles_id",\n                        pa.array(outputs.ravel()),\n                        dora_input["metadata"],\n                    )\n\n        return DoraStatus.CONTINUE\n\n\n'))))}c.isMDXComponent=!0}}]);