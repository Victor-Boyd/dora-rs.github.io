"use strict";(self.webpackChunkdora_rs_github_io=self.webpackChunkdora_rs_github_io||[]).push([[2501],{3905:(e,n,t)=>{t.d(n,{Zo:()=>d,kt:()=>_});var r=t(7294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var s=r.createContext({}),p=function(e){var n=r.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},d=function(e){var n=p(e.components);return r.createElement(s.Provider,{value:n},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},c=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=p(t),c=a,_=u["".concat(s,".").concat(c)]||u[c]||m[c]||o;return t?r.createElement(_,i(i({ref:n},d),{},{components:t})):r.createElement(_,i({ref:n},d))}));function _(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=c;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[u]="string"==typeof e?e:a,i[1]=l;for(var p=2;p<o;p++)i[p]=t[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}c.displayName="MDXCreateElement"},5580:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var r=t(7462),a=(t(7294),t(3905));const o={},i="MiDaS (Mixed Frequency Data Sampling Regression Models, \u6df7\u9891\u6570\u636e\u91c7\u6837\u56de\u5f52\u6a21\u578b)",l={unversionedId:"nodes_operators/midas_op",id:"nodes_operators/midas_op",title:"MiDaS (Mixed Frequency Data Sampling Regression Models, \u6df7\u9891\u6570\u636e\u91c7\u6837\u56de\u5f52\u6a21\u578b)",description:"\u7528\u4e8e\u4ece\u5355\u4e2a\u56fe\u50cf\u8ba1\u7b97\u76f8\u5bf9\u6df1\u5ea6\u7684 MiDaS \u6a21\u578b (Mixed Frequency Data Sampling Regression Models, \u6df7\u9891\u6570\u636e\u91c7\u6837\u56de\u5f52\u6a21\u578b) \u3002",source:"@site/i18n/zh-CN/docusaurus-plugin-content-docs/current/nodes_operators/midas_op.md",sourceDirName:"nodes_operators",slug:"/nodes_operators/midas_op",permalink:"/zh-CN/docs/nodes_operators/midas_op",draft:!1,editUrl:"https://crowdin.com/dora-rs/zh-CN",tags:[],version:"current",frontMatter:{},sidebar:"nodes_operators",previous:{title:"FOT( Frenet Optimal Planner, Frenet \u6700\u4f18\u89c4\u5212\u5e08) \u64cd\u4f5c\u7b26",permalink:"/zh-CN/docs/nodes_operators/fot_op"},next:{title:"Obstacle location (\u969c\u788d\u7269\u4f4d\u7f6e) \u64cd\u4f5c\u7b26",permalink:"/zh-CN/docs/nodes_operators/obstacle_location_op"}},s={},p=[{value:"\u5b89\u88c5\uff1a",id:"\u5b89\u88c5",level:3},{value:"\u8f93\u5165",id:"\u8f93\u5165",level:2},{value:"\u8f93\u51fa",id:"\u8f93\u51fa",level:2},{value:"\u793a\u4f8b\u8f93\u51fa",id:"\u793a\u4f8b\u8f93\u51fa",level:2},{value:"\u65b9\u6cd5",id:"\u65b9\u6cd5",level:2},{value:"<code>__init__()</code>",id:"__init__",level:3},{value:"<code>.on_event(...)</code>",id:"on_event",level:3},{value:"<code>.on_input(...)</code>",id:"on_input",level:3}],d={toc:p},u="wrapper";function m(e){let{components:n,...t}=e;return(0,a.kt)(u,(0,r.Z)({},d,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"midas-mixed-frequency-data-sampling-regression-models-\u6df7\u9891\u6570\u636e\u91c7\u6837\u56de\u5f52\u6a21\u578b"},"MiDaS (Mixed Frequency Data Sampling Regression Models, \u6df7\u9891\u6570\u636e\u91c7\u6837\u56de\u5f52\u6a21\u578b)"),(0,a.kt)("p",null,"\u7528\u4e8e\u4ece\u5355\u4e2a\u56fe\u50cf\u8ba1\u7b97\u76f8\u5bf9\u6df1\u5ea6\u7684 MiDaS \u6a21\u578b (Mixed Frequency Data Sampling Regression Models, \u6df7\u9891\u6570\u636e\u91c7\u6837\u56de\u5f52\u6a21\u578b) \u3002"),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"MiDaS \u4ece\u5355\u4e2a\u56fe\u50cf\u8ba1\u7b97\u76f8\u5bf9\u53cd\u5411\u6df1\u5ea6\u3002 \u8be5\u5b58\u50a8\u5e93\u63d0\u4f9b\u4e86\u591a\u4e2a\u6a21\u578b\uff0c\u6db5\u76d6\u4e0d\u540c\u7684\u7528\u4f8b\uff0c\u4ece\u5c0f\u578b\u9ad8\u901f\u6a21\u578b\u5230\u63d0\u4f9b\u6700\u9ad8\u7cbe\u5ea6\u7684\u8d85\u5927\u578b\u6a21\u578b\u3002 \u8fd9\u4e9b\u6a21\u578b\u5df2\u4f7f\u7528\u591a\u76ee\u6807\u4f18\u5316\u5728 10 \u4e2a\u4e0d\u540c\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bad\u7ec3\uff0c\u4ee5\u786e\u4fdd\u5728\u5404\u79cd\u8f93\u5165\u4e0a\u83b7\u5f97\u9ad8\u8d28\u91cf\u3002")),(0,a.kt)("h3",{id:"\u5b89\u88c5"},"\u5b89\u88c5\uff1a"),(0,a.kt)("p",null,"midas \u79bb\u7ebf\u5b89\u88c5\uff1a"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cd $DORA_DEP_HOME/dependencies/\ngit clone git@github.com:isl-org/MiDaS.git\ncd MiDaS/weights\n# \u5982\u679c\u4e0d\u60f3\u6dfb\u52a0\u624b\u52a8\u4e0b\u8f7d\uff0c\u7a0b\u5e8f\u5c06\u4f1a\u81ea\u52a8\u4e0b\u8f7d\u6a21\u578b\u6587\u4ef6\nwget https://github.com/isl-org/MiDaS/releases/download/v2_1/midas_v21_small_256.pt\ncp midas_v21_small_256.pt $HOME/.cache/torch/hub/checkpoints/\n")),(0,a.kt)("h2",{id:"\u8f93\u5165"},"\u8f93\u5165"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u56fe\u50cf: \u9ad8 x \u5bbd x BGR array.")),(0,a.kt)("h2",{id:"\u8f93\u51fa"},"\u8f93\u51fa"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"bbox: \u9ad8 x \u5bbd x \u76f8\u5bf9\u6df1\u5ea6\u6570\u7ec4\u3002")),(0,a.kt)("h2",{id:"\u793a\u4f8b\u8f93\u51fa"},"\u793a\u4f8b\u8f93\u51fa"),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://i.imgur.com/UrF9iPN.png",alt:"Imgur"})),(0,a.kt)("p",null,"\u6dfb\u52a0\u4ee5\u4e0b\u6570\u636e\u6d41\u914d\u7f6e"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-yaml"},'  - id: midas_op\n    operator:\n      outputs:\n        - depth_frame\n      inputs:\n        image: webcam/image\n      python: ../../operators/midas_op.py\n    env:\n      PYTORCH_DEVICE: "cuda"\n      MIDAS_PATH: $DORA_DEP_HOME/dependencies/MiDaS/\n      MIDAS_WEIGHT_PATH: $DORA_DEP_HOME/dependencies/MiDaS/weights/midas_v21_small_256.pt\n      MODEL_TYPE: "MiDaS_small"\n      MODEL_NAME: "MiDaS_small"\n')),(0,a.kt)("blockquote",null,(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},'model_type = "DPT_Large"     # MiDaS v3 - Large     (\u6700\u9ad8\u7cbe\u5ea6\uff0c\u6700\u6162\u7684\u63a8\u7406\u901f\u5ea6)'),(0,a.kt)("li",{parentName:"ul"},'model_type = "DPT_Hybrid"   # MiDaS v3 - Hybrid    (\u4e2d\u7b49\u7cbe\u5ea6\uff0c\u4e2d\u7b49\u63a8\u7406\u901f\u5ea6)'),(0,a.kt)("li",{parentName:"ul"},'model_type = "MiDaS_small"  # MiDaS v2.1 - Small   (\u6700\u4f4e\u7cbe\u5ea6\uff0c\u6700\u9ad8\u63a8\u7406\u901f\u5ea6)'))),(0,a.kt)("h2",{id:"\u65b9\u6cd5"},"\u65b9\u6cd5"),(0,a.kt)("h3",{id:"__init__"},(0,a.kt)("inlineCode",{parentName:"h3"},"__init__()")),(0,a.kt)("details",null,(0,a.kt)("summary",null,"\u6e90\u7801"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'    def __init__(self):\n        if MIDAS_PATH is None:\n            # \u53ef\u80fd\u9700\u8981\u4e92\u8054\u7f51\n            self.model = torch.hub.load(\n                "intel-isl/MiDaS",\n                MODEL_TYPE,\n            )\n            midas_transforms = torch.hub.load("intel-isl/MiDaS", "transforms")\n        else:\n            # \u5927\u6982\u4e0d\u9700\u8981\u4e92\u8054\u7f51\n            self.model = torch.hub.load(\n                repo_or_dir=MIDAS_PATH,\n                model=MODEL_NAME,\n                weights=MIDAS_WEIGHT_PATH,\n                source="local",\n            )\n            midas_transforms = torch.hub.load(\n                repo_or_dir=MIDAS_PATH, model="transforms", source="local"\n            )\n        if MODEL_TYPE == "DPT_Large" or MODEL_TYPE == "DPT_Hybrid":\n            self.transform = midas_transforms.dpt_transform\n        else:\n            self.transform = midas_transforms.small_transform\n        self.model.to(torch.device(DEVICE))\n        self.model.eval()\n\n\n'))),(0,a.kt)("h3",{id:"on_event"},(0,a.kt)("inlineCode",{parentName:"h3"},".on_event(...)")),(0,a.kt)("details",null,(0,a.kt)("summary",null,"\u6e90\u7801"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\n    def on_event(\n        self,\n        dora_event: dict,\n        send_output: Callable[[str, bytes], None],\n    ) -> DoraStatus:\n        if dora_event["type"] == "INPUT":\n            return self.on_input(dora_event, send_output)\n        return DoraStatus.CONTINUE\n\n\n'))),(0,a.kt)("h3",{id:"on_input"},(0,a.kt)("inlineCode",{parentName:"h3"},".on_input(...)")),(0,a.kt)("p",null,"\u56fe\u50cf\u53e5\u67c4 \u53c2\u6570: dora_input","[",'"id"',"]","  (str): yaml \u914d\u7f6e\u4e2d\u58f0\u660e\u7684\u8f93\u5165\u7684Id dora_input","[",'"data"',"]"," (bytes): \u5b57\u8282\u5f62\u5f0f\u7684\u8f93\u5165\u6d88\u606f send_output (Callable[","[str, bytes]","]): \u51fd\u6570\u4f7f\u8f93\u51fa\u53d1\u9001\u56dedora\u3002"),(0,a.kt)("details",null,(0,a.kt)("summary",null,"\u6e90\u7801"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'\n    def on_input(\n        self,\n        dora_input: dict,\n        send_output: Callable[[str, bytes], None],\n    ) -> DoraStatus:\n        """\u56fe\u50cf\u53e5\u67c4\n        \u53c2\u6570:\n            dora_input["id"]  (str): yaml \u914d\u7f6e\u4e2d\u58f0\u660e\u7684\u8f93\u5165\u7684Id\n            dora_input["data"] (bytes): \u5b57\u8282\u5f62\u5f0f\u7684\u8f93\u5165\u6d88\u606f\n            send_output (Callable[[str, bytes]]): \u51fd\u6570\u4f7f\u8f93\u51fa\u53d1\u9001\u56dedora\u3002\n        """\n        if dora_input["id"] == "image":\n            # \u8f6c\u6362 bytes \u7c7b\u578b \u81f3 numpy array \u7c7b\u578b\n            frame = np.frombuffer(\n                dora_input["data"],\n                np.uint8,\n            ).reshape((IMAGE_HEIGHT, IMAGE_WIDTH, 4))\n\n            with torch.no_grad():\n                image = frame[:, :, :3]\n                img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n                input_batch = self.transform(img).to(DEVICE)\n                prediction = self.model(input_batch)\n                prediction = torch.nn.functional.interpolate(\n                    prediction.unsqueeze(1),\n                    size=img.shape[:2],\n                    mode="bicubic",\n                    align_corners=False,\n                ).squeeze()\n                depth_output = prediction.cpu().numpy()\n                depth_min = depth_output.min()\n                depth_max = depth_output.max()\n                normalized_depth = (\n                    255 * (depth_output - depth_min) / (depth_max - depth_min)\n                )\n                normalized_depth *= 3\n                depth_frame = (\n                    np.repeat(np.expand_dims(normalized_depth, 2), 3, axis=2) / 3\n                )\n                depth_frame = cv2.applyColorMap(\n                    np.uint8(depth_frame), cv2.COLORMAP_INFERNO\n                )\n                height, width = depth_frame.shape[:2]\n                depth_frame_4 = np.dstack(\n                    [depth_frame, np.ones((height, width), dtype="uint8") * 255]\n                )\n\n                send_output(\n                    "depth_frame",\n                    depth_frame_4.tobytes(),\n                    dora_input["metadata"],\n                )\n        return DoraStatus.CONTINUE\n\n\n'))))}m.isMDXComponent=!0}}]);